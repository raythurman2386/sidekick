OLLAMA_HOST="http://localhost:11434"
AI_MODEL="llama2"  # or your preferred model